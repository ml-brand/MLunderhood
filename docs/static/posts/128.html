<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ML Underhood — пост #128</title>
  <meta name="description" content=" Yandex Research везёт на ICML 2025 шесть статей   Шесть работ российских исследователей из Яндекса приняли на  ICML  (International Conference on Machine Learning) — одну из старейших и самых авторит" />
  <link rel="icon" href="../../favicon.ico" sizes="any" />
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32.png" />
  <link rel="apple-touch-icon" href="../../apple-touch-icon.png" />

  <link rel="canonical" href="https://ml-brand.github.io/MLunderhood/static/posts/128.html" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="ML Underhood — пост #128" />
  <meta property="og:description" content=" Yandex Research везёт на ICML 2025 шесть статей   Шесть работ российских исследователей из Яндекса приняли на  ICML  (International Conference on Machine Learning) — одну из старейших и самых авторит" />
  
  <meta property="article:published_time" content="2025-07-10T13:25:01+00:00" />
  <meta property="article:author" content="ML Underhood" />
  <meta name="twitter:card" content="summary" />
  
  <link rel="stylesheet" href="../../style.css" />
  <script src="../../metrika.js"></script>
</head>
<body data-index-href="../page-2.html">
  <header class="header">
    <div class="container">
      <div class="title-grid single-title">
        <a class="grid-avatar" href="#" target="_blank" rel="noopener">
          <img id="channelAvatar" class="channel-avatar" src="../../assets/channel_avatar.jpg" alt="Аватар канала"  />
        </a>
        <div class="grid-main">
          <div class="title-head">
            <a class="back-link" href="../page-2.html">← Ко всем постам</a>
            <a class="badge-chip" id="siteTitleWrap" href="#" target="_blank" rel="noopener"><h1 id="siteTitle">ML Underhood</h1></a>
            <div class="hero-actions">
              <a id="subscribeBtn" class="subscribe-btn" href="https://t.me/+pMU3hEMtRO5jMzQy" target="_blank" rel="noopener" >Подписаться</a>
              <a class="icon-btn" href="../../post.html?id=128" aria-label="Открыть динамическую страницу поста">↺</a>
              <button id="themeToggle" class="icon-btn" type="button" aria-label="Переключить тему"></button>
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>

  
  <div id="promoBanner" class="promo-banner" hidden>
    <div class="container promo-inner">
      <span class="promo-text"><a href="https://t.me/addlist/5NH3RoVejEI1MGEy">Подпишись на все наши ML каналы. Они классные, отвечаем!</a></span>
      <button id="promoClose" class="promo-close" type="button" aria-label="Скрыть плашку">×</button>
    </div>
  </div>
  

  <main class="container single-page">
    <article id="postContainer" class="post post-page" data-post-id="128">
      <div class="post-header">
        <div class="right"><span class="post-date" data-iso-date="2025-07-10T13:25:01+00:00">2025-07-10 13:25 UTC</span></div>
      </div>
      <div class="post-body"><strong>Yandex Research везёт на ICML 2025 шесть статей</strong><br><br>Шесть работ российских исследователей из Яндекса приняли на <a href="https://icml.cc/" rel="nofollow noopener noreferrer">ICML</a> (International Conference on Machine Learning) — одну из старейших и самых авторитетных в мире научных конференций по ИИ, которая входит в топ-3 согласно Google Scholar. Статьи посвящены различным аспектам машинного обучения — от алгоритмического мышления нейронных сетей и измерения разнообразия до оптимизации использования памяти при работе с большими языковыми моделями. Кратко рассказываем о каждой из них — подробнее можно почитать <a href="https://research.yandex.com/blog/papers-accepted-to-icml-2025" rel="nofollow noopener noreferrer">в блоге</a> Yandex Research.<br><br><a href="https://arxiv.org/abs/2402.11628" rel="nofollow noopener noreferrer"><strong>Discrete Neural Algorithmic Reasoning<br></strong></a>Авторы исследуют причины, по которым нейросетевые модели плохо обобщаются при обучении на алгоритмические задачи, и предлагают архитектурные изменения, решающие эту проблему. В частности, вводят ограничение на представление состояний вычислений, что обеспечивает точное соответствие исходным алгоритмам. Этот подход позволил добиться чёткого выполнения нейросетью нескольких алгоритмов. Кроме того, предложенная архитектура даёт возможность строго доказывать корректность работы обученных моделей на любых входных данных.<br><br><a href="https://arxiv.org/abs/2410.14556" rel="nofollow noopener noreferrer"><strong>Measuring Diversity: Axioms and Challenges</strong></a><br>В работе анализируют метрики разнообразия и выделяют три свойства, которым должна удовлетворять хорошая метрика: монотонность, уникальность и непрерывность. Существующие метрики не удовлетворяют хотя бы одному из этих свойств. При этом в работе приведены примеры метрик, которые удовлетворяют всем, но их вычисление — NP-трудная задача. Вопрос о том, существуют ли эффективные метрики со всеми желаемыми свойствами, остаётся открытым.<br><br><a href="https://arxiv.org/abs/2501.19392" rel="nofollow noopener noreferrer"><strong>Cache Me If You Must: Adaptive Key-Value Quantization for Large Language Models</strong></a> <br>LLM хранят ключи (K) и значения (V) внимания для каждого токена, что быстро расходует память. Авторы предлагают сжимать их не в исходном виде, а с учётом взаимной информации между слоями — кодировать только то, что нельзя предсказать по соседнему слою линейными предикторами. Это позволяет сжимать KV-вектора почти без потерь качества даже при экстремальном 2-битном квантовании.<br><br><a href="https://arxiv.org/abs/2411.07837" rel="nofollow noopener noreferrer"><strong>FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training</strong></a> <br>При увеличении размеров обучаемой модели для хранения статистик оптимизатора требуется огромное количество памяти. Предыдущие методы уменьшали эту нагрузку, проецируя градиент на малоранговое пространство, где и хранились статистики оптимизатора. Однако такой подход не использует всю информацию из градиента. Авторы FRUGAL предлагают решить эту проблему, разделяя градиент на две части, одна из которых используется для обновления в малоранговом подпространстве через Adam, а вторая — в оставшемся подпространстве с помощью оптимизатора без статистик, например SGD или signSGD. Метод стабильно превосходит другие подходы при ограниченных ресурсах, достигая лучших результатов в предобучении и дообучении при той же экономии памяти.<br><br><a href="https://arxiv.org/abs/2502.01362" rel="nofollow noopener noreferrer"><strong>Inverse Bridge Matching Distillation <br></strong></a>Авторы предлагают алгоритм дистилляции diffusion bridge-модели (DBM) для задачи image-to-image translation до одного шага. Метод работает как для условных, так и безусловных моделей, может применяться для широкого класса задач реконструкции и генерации изображений, а также ускоряет работу моделей в 4–100 раз. В некоторых задачах модель-ученик даёт результат лучше, чем модель-учитель.<br><br><a href="https://arxiv.org/abs/2410.14649" rel="nofollow noopener noreferrer"><strong>EvoPress: Towards Optimal Dynamic Model Compression via Evolutionary Search</strong></a> <br>EvoPress — метод оптимального динамического сжатия больших языковых моделей, основанный на применении эволюционного алгоритма. Он учитывает сложную нелинейную взаимосвязь между разными слоями нейронной сети. Подход валидируют на семействах моделей Llama, Mistral и Phi, где EvoPress достигает более высокого качества по сравнению с однородным сжатием и конкурентными динамическими методами.<br><br>В этом году конференция будет проходить с 13 по 19 июля в Ванкувере, и её по традиции посетят ML-инженеры из Яндекса. Ну а мы будем рассказывать о самых интересных статьях и докладах.<br><br><a href="https://t.me/+yaGEbJ4stulhZmYy" rel="nofollow noopener noreferrer">ML Underhood</a><br><br>#YaICML25</div>
      <div class="actions">
        <span>2 134 просмотров · 50 реакций</span>
        <span class="action-links"><a href="https://t.me/MLunderhood/128" target="_blank" rel="noopener">Открыть в Telegram</a> · <a href="../page-2.html">К списку постов</a> · <a href="./128.html">Ссылка на этот пост</a></span>
      </div>
    </article>

    <div class="pager single-nav">
      <a id="prevPost" class="nav-link" href="./130.html" style="visibility:visible">← Более новый</a>
      <a id="nextPost" class="nav-link" href="./124.html" style="visibility:visible">Более старый →</a>
    </div>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="footer-inner">
        <span>based on <a href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">tg-to-gh-pages</a> (created by <a href="https://github.com/ml-brand" target="_blank" rel="noopener">ML Brand</a>)</span>
        <a id="repoLink" href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">Do the same with your channel.</a>
        <span class="footer-links">
          static copy ·
          <a href="../../feed.xml" target="_blank" rel="noopener">RSS</a> ·
          <a href="../../atom.xml" target="_blank" rel="noopener">Atom</a>
        </span>
      </div>
    </div>
  </footer>

  <script>
    window.__STATIC_POSTS = [{"id": 128, "media": []}];
    window.__STATIC_META = {"title": "ML Underhood", "username": "MLunderhood", "channel": "MLunderhood", "last_sync_utc": "2026-02-10T08:32:52Z", "posts_count": 111, "last_seen_message_id": 283, "stats": {"new": 161, "updated": 4, "media_downloaded": 161}, "avatar": "assets/channel_avatar.jpg", "meta_schema_version": "1.0.0", "posts_schema_version": "1.0.0"};
  </script>
  <script src="../../common.js"></script>
  <script src="../../static.js"></script>
</body>
</html>
