<!doctype html>
<html lang="ru">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>ML Underhood — пост #131</title>
  <meta name="description" content=" ICML 2025: интересные доклады на тему ML — часть 1   В эти дни в Ванкувере стартовала ICML 2025. Инженеры Яндекса делятся первой порцией любопытных работ прямо с места событий.     Efficient Distribu" />
  <link rel="icon" href="../../favicon.ico" sizes="any" />
  <link rel="icon" type="image/png" sizes="32x32" href="../../favicon-32.png" />
  <link rel="apple-touch-icon" href="../../apple-touch-icon.png" />

  <link rel="canonical" href="https://ml-brand.github.io/MLunderhood/static/posts/131.html" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="ML Underhood — пост #131" />
  <meta property="og:description" content=" ICML 2025: интересные доклады на тему ML — часть 1   В эти дни в Ванкувере стартовала ICML 2025. Инженеры Яндекса делятся первой порцией любопытных работ прямо с места событий.     Efficient Distribu" />
  <meta property="og:image" content="https://ml-brand.github.io/MLunderhood/assets/media/thumbs/131_480.webp" />
  <meta property="og:image:alt" content="ML Underhood" />
  <meta property="article:published_time" content="2025-07-17T08:51:15+00:00" />
  <meta property="article:author" content="ML Underhood" />
  <meta name="twitter:card" content="summary_large_image" />
  <meta name="twitter:image" content="https://ml-brand.github.io/MLunderhood/assets/media/thumbs/131_480.webp" />
  <link rel="stylesheet" href="../../style.css" />
  <script src="../../metrika.js"></script>
</head>
<body data-index-href="../page-2.html">
  <header class="header">
    <div class="container">
      <div class="title-grid single-title">
        <a class="grid-avatar" href="#" target="_blank" rel="noopener">
          <img id="channelAvatar" class="channel-avatar" src="../../assets/channel_avatar.jpg" alt="Аватар канала"  />
        </a>
        <div class="grid-main">
          <div class="title-head">
            <a class="back-link" href="../page-2.html">← Ко всем постам</a>
            <a class="badge-chip" id="siteTitleWrap" href="#" target="_blank" rel="noopener"><h1 id="siteTitle">ML Underhood</h1></a>
            <div class="hero-actions">
              <a id="subscribeBtn" class="subscribe-btn" href="https://t.me/+pMU3hEMtRO5jMzQy" target="_blank" rel="noopener" >Подписаться</a>
              <a class="icon-btn" href="../../post.html?id=131" aria-label="Открыть динамическую страницу поста">↺</a>
              <button id="themeToggle" class="icon-btn" type="button" aria-label="Переключить тему"></button>
            </div>
          </div>
        </div>
      </div>
    </div>
  </header>

  
  <div id="promoBanner" class="promo-banner" hidden>
    <div class="container promo-inner">
      <span class="promo-text"><a href="https://t.me/addlist/5NH3RoVejEI1MGEy">Подпишись на все наши ML каналы. Они классные, отвечаем!</a></span>
      <button id="promoClose" class="promo-close" type="button" aria-label="Скрыть плашку">×</button>
    </div>
  </div>
  

  <main class="container single-page">
    <article id="postContainer" class="post post-page" data-post-id="131">
      <div class="post-header">
        <div class="right"><span class="post-date" data-iso-date="2025-07-17T08:51:15+00:00">2025-07-17 08:51 UTC</span></div>
      </div>
      <div class="post-body"><strong>ICML 2025: интересные доклады на тему ML — часть 1</strong><br><br>В эти дни в Ванкувере стартовала ICML 2025. Инженеры Яндекса делятся первой порцией любопытных работ прямо с места событий. <br><br><a href="https://arxiv.org/abs/2502.04164" rel="nofollow noopener noreferrer"><strong>Efficient Distributed Optimization under Heavy-Tailed Noise</strong></a><strong><br></strong><br>Авторы пытаются бороться с шумными апдейтами без дополнительной памяти. Вводят два гиперпараметра: «верхний порог» и «нижний порог», но при этом не просто обрезают градиенты по порогам, а делают это необычным способом, получая более качественную оптимизацию. Достоинство метода — в его stateless-сущности и экономии памяти, недостаток — в необходимость подбирать два новых гиперпараметра. Существующие методы, вроде AMSgrad, делают примерно то же самое: борются с взрывными апдейтами, но с использованием дополнительной памяти. Огорчает, что нет сравнения с AMSgrad — старый stateful-метод VS новый stateless-метод.<br><br><a href="https://icml.cc/virtual/2025/poster/45619" rel="nofollow noopener noreferrer"><strong>Online Conformal Prediction via Online Optimization</strong></a><br><br>Несмотря на немного обескураживающее название, под капотом — онлайн-обучение квантильной регрессии (алгоритм оптимизации разработан специально для неё). На постере нет оценок на regret, однако авторы заверили, что их можно получить, поскольку это узкая задача из уже изученного более широкого семейства.<br><br><a href="https://arxiv.org/abs/2411.07120" rel="nofollow noopener noreferrer"><strong>Lean and Mean Adaptive Optimization via Subset-Norm and Subspace-Momentum with Convergence Guarantees</strong></a><br><br>Сугубо теоретическая статья, практические применения которой уже можно было видеть. AdaGrad, Adam, RMSprop — покоординатные адаптивные lr. Есть другая крайность — один нормализатор на все параметры (что делает метод фактически SGD, только чуть более простым в подборе гиперпараметров). Авторы исследуют нечто среднее: делят параметры на группы и для каждой вычисляют нормализатор из нормы вектора градиентов. Во‑первых, авторы выписали оценки сходимости для ряда задач, во‑вторых — провели эксперименты с трансформерами для выбора оптимальных групп параметров. Из личного разговора с исследователем удалось узнать, что лучше брать матрицы целиком — поколоночные и построчные группы работают хуже и покоординатного метода, и предложенного метода.<br><br><a href="https://icml.cc/virtual/2025/poster/44556" rel="nofollow noopener noreferrer"><strong>Global curvature for second-order optimization of neural networks</strong></a><br><br>Метод второго порядка для оптимизации нейросетей. Смысл такой же, как в классических подходах: давайте будем считать произведение обратного квадратного корня гессиана на градиент как-нибудь побыстрее. Авторы статьи говорят: вычисление feed forward-архитектур устойчиво к некоторым перестановкам в матрицах весов линейных проекций — и некоторыми похожими свойствами обладает гессиан. Из этого свойства они получают вычислительно более эффективный метод. Разные методы оптимизации предлагают разные способы считать произведение обратного квадратного корня гессиана на градиент. Самые известные методы для large scale-задач — BFGS и L-BFGS. Пообщались с авторами статей — они заявляют, что их метод лучше для их архитектур, потому что он ищет среди точных решений (с учётом исследуемого ими свойства устойчивости к перестановкам), а семейства BFSG используют low-rank аппроксимацию, то есть не дают точного решения. Формулы выписаны только для tanh-активации. Пожелаем авторам удачи — хочется увидеть фундаментальный сдвиг в качестве методов оптимизации и асимптотике сходимости, а не очередной «Adam с рюшечками».<br><br><em>Интересное отобрал </em><em><tg-emoji emoji-id="5224192932302565805">❣</tg-emoji></em><em> Алексей Морозов</em><br><br><a href="https://t.me/+yaGEbJ4stulhZmYy" rel="nofollow noopener noreferrer">ML Underhood</a><br><br>#YaICML25<div class="media"><img class="media-img" loading="lazy" src="../../assets/media/thumbs/131_480.webp" srcset="../../assets/media/thumbs/131_480.webp 480w, ../../assets/media/131.jpg 1200w" sizes="(max-width: 768px) 100vw, 800px" alt="" data-post-id="131" data-image-index="0" /></div></div>
      <div class="actions">
        <span>1 506 просмотров · 16 реакций</span>
        <span class="action-links"><a href="https://t.me/MLunderhood/131" target="_blank" rel="noopener">Открыть в Telegram</a> · <a href="../page-2.html">К списку постов</a> · <a href="./131.html">Ссылка на этот пост</a></span>
      </div>
    </article>

    <div class="pager single-nav">
      <a id="prevPost" class="nav-link" href="./132.html" style="visibility:visible">← Более новый</a>
      <a id="nextPost" class="nav-link" href="./130.html" style="visibility:visible">Более старый →</a>
    </div>
  </main>

  <footer class="footer">
    <div class="container">
      <div class="footer-inner">
        <span>based on <a href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">tg-to-gh-pages</a> (created by <a href="https://github.com/ml-brand" target="_blank" rel="noopener">ML Brand</a>)</span>
        <a id="repoLink" href="https://github.com/ml-brand/tg-to-gh-pages" target="_blank" rel="noopener">Do the same with your channel.</a>
        <span class="footer-links">
          static copy ·
          <a href="../../feed.xml" target="_blank" rel="noopener">RSS</a> ·
          <a href="../../atom.xml" target="_blank" rel="noopener">Atom</a>
        </span>
      </div>
    </div>
  </footer>

  <script>
    window.__STATIC_POSTS = [{"id": 131, "media": [{"kind": "photo", "path": "../../assets/media/131.jpg", "thumb": "../../assets/media/thumbs/131_480.webp", "size": 148299, "mime": "image/jpeg", "name": null}]}];
    window.__STATIC_META = {"title": "ML Underhood", "username": "MLunderhood", "channel": "MLunderhood", "last_sync_utc": "2026-02-14T09:05:16Z", "posts_count": 111, "last_seen_message_id": 283, "stats": {"new": 161, "updated": 29, "media_downloaded": 161}, "avatar": "assets/channel_avatar.jpg", "meta_schema_version": "1.0.0", "posts_schema_version": "1.0.0"};
  </script>
  <script src="../../common.js"></script>
  <script src="../../static.js"></script>
</body>
</html>
